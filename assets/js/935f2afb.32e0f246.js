"use strict";(globalThis.webpackChunkphysical_ai_humanoid_book=globalThis.webpackChunkphysical_ai_humanoid_book||[]).push([[581],{5610:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"Feature Specification: Physical AI & Humanoid Robotics Textbook","href":"/docs/introduction","docId":"introduction"},{"type":"link","label":"Implementation Plan: [FEATURE]","href":"/docs/implementation-plan","docId":"implementation-plan"},{"type":"link","label":"Chapter 1: Introduction to Physical AI","href":"/docs/chapter1","docId":"chapter1"},{"type":"link","label":"Chapter 2: Robotics Fundamentals","href":"/docs/chapter2","docId":"chapter2"},{"type":"link","label":"Chapter 3: Sensing and Perception","href":"/docs/chapter3","docId":"chapter3"},{"type":"link","label":"Chapter 4: Actuation and Control","href":"/docs/chapter4","docId":"chapter4"},{"type":"link","label":"Chapter 5: Robot Kinematics and Dynamics","href":"/docs/chapter5","docId":"chapter5"},{"type":"link","label":"Welcome to the Physical AI & Humanoid Robotics Textbook","href":"/docs/","docId":"index"},{"type":"link","label":"Module 1: The Robotic Nervous System (ROS 2)","href":"/docs/module1-ros2","docId":"module1-ros2"},{"type":"link","label":"Module 2: The Digital Twin (Gazebo & Unity)","href":"/docs/module2-digital-twin","docId":"module2-digital-twin"},{"type":"link","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","href":"/docs/module3-ai-robot-brain","docId":"module3-ai-robot-brain"},{"type":"link","label":"Module 4: Vision-Language-Action (VLA)","href":"/docs/module4-vla","docId":"module4-vla"},{"type":"category","label":"New Modules","items":[{"type":"link","label":"Module 1: The Robotic Nervous System (ROS 2)","href":"/docs/module1-ros2","docId":"module1-ros2"},{"type":"link","label":"Module 2: The Digital Twin (Gazebo & Unity)","href":"/docs/module2-digital-twin","docId":"module2-digital-twin"},{"type":"link","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","href":"/docs/module3-ai-robot-brain","docId":"module3-ai-robot-brain"},{"type":"link","label":"Module 4: Vision-Language-Action (VLA)","href":"/docs/module4-vla","docId":"module4-vla"}],"collapsed":true,"collapsible":true}]},"docs":{"chapter1":{"id":"chapter1","title":"Chapter 1: Introduction to Physical AI","description":"1.1 What is Physical AI?","sidebar":"tutorialSidebar"},"chapter2":{"id":"chapter2","title":"Chapter 2: Robotics Fundamentals","description":"2.1 Definition of Robotics","sidebar":"tutorialSidebar"},"chapter3":{"id":"chapter3","title":"Chapter 3: Sensing and Perception","description":"3.1 Introduction to Sensors","sidebar":"tutorialSidebar"},"chapter4":{"id":"chapter4","title":"Chapter 4: Actuation and Control","description":"4.1 Actuators in Robotics","sidebar":"tutorialSidebar"},"chapter5":{"id":"chapter5","title":"Chapter 5: Robot Kinematics and Dynamics","description":"5.1 Advanced Kinematics","sidebar":"tutorialSidebar"},"implementation-plan":{"id":"implementation-plan","title":"Implementation Plan: [FEATURE]","description":"Branch \\"[DATE]\\" | Spec: \\"[link]\\"","sidebar":"tutorialSidebar"},"index":{"id":"index","title":"Welcome to the Physical AI & Humanoid Robotics Textbook","description":"This is the introductory page for the textbook.","sidebar":"tutorialSidebar"},"introduction":{"id":"introduction","title":"Feature Specification: Physical AI & Humanoid Robotics Textbook","description":"Feature Branch: 001-physical-ai-robotics-textbook","sidebar":"tutorialSidebar"},"module1-ros2":{"id":"module1-ros2","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"ROS 2 (Robot Operating System 2) provides a flexible framework for writing robot software. It encompasses a collection of tools, libraries, and conventions designed to simplify the process of creating complex and robust robot applications across diverse hardware and environments. Its distributed architecture supports modular development, enabling components to communicate seamlessly and be deployed independently, making it ideal for scalable robotic systems.","sidebar":"tutorialSidebar"},"module2-digital-twin":{"id":"module2-digital-twin","title":"Module 2: The Digital Twin (Gazebo & Unity)","description":"Digital twins are virtual models designed to accurately reflect a physical object or system, updating in real-time with data from their physical counterparts. In robotics, platforms like Gazebo and Unity facilitate the creation of these digital twins, offering realistic simulation environments where robots can be designed, tested, and optimized without the need for physical hardware. This capability is crucial for rapid prototyping, algorithm development, and training AI models in a safe, controlled, and cost-effective manner.","sidebar":"tutorialSidebar"},"module3-ai-robot-brain":{"id":"module3-ai-robot-brain","title":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","description":"NVIDIA Isaac is a comprehensive platform for accelerating the development and deployment of AI-powered robots. It provides a suite of tools, SDKs, and a robotics simulation platform to build, train, and test advanced robotic applications. Isaac integrates perception, navigation, manipulation, and human-robot interaction capabilities, leveraging NVIDIA\'s GPU technology to deliver high-performance AI inference and complex simulation environments, essentially acting as the intelligent \'brain\' for next-generation robots.","sidebar":"tutorialSidebar"},"module4-vla":{"id":"module4-vla","title":"Module 4: Vision-Language-Action (VLA)","description":"Vision-Language-Action (VLA) models represent a frontier in AI, integrating capabilities from computer vision, natural language processing, and robotic control. These models enable robots to understand complex human commands, interpret visual information from their environment, and translate this understanding into physical actions. By combining visual perception with linguistic comprehension, VLA systems empower robots to interact more intuitively and effectively with the real world, performing tasks that require nuanced understanding and flexible execution.","sidebar":"tutorialSidebar"}}}')}}]);